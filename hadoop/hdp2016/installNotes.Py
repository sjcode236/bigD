
passwd hadoop
hd123


vi /etc/hosts
192.168.56.131  centosNN
192.168.56.132  centosNN2
192.168.56.141  centosDN
192.168.56.142  centosDN2
192.168.56.143  centosDN3

chkconfig ntpd on
service ntpd start
chkconfig --list ntpd

cd /etc/yum.repos.d
wget  http://public-repo-1.hortonworks.com/ambari/centos6/1.x/updates/1.4.3.38/ambari.repo

http://capnjosh.com/blog/installing-hortonworks-hadoop-ambari-server/

===================================================
Ambari Install Guide from  hotron works 

===============================================================
day to day work
queing  mechanisam ;

monitorning hadopp : enclia ; ganglia ;Nagios ; splunk

kerbros ; how to set rules and configure

performance  tuning ;
how to limit the resource allocated to a process or job

how to set  diskfail  tolerance 

how to trouble shoot hive query fail 

how to use distcp 


oozie ; flume ; ; hbase , hive , kafka , spark
set SSL security 
hadoop 2.3 
============================================================
____________Requirements ___________________
- L3/4 level Hadoop admin who can work independently with excellent communication skill.
- Good knowledge of Linux (security, configuration, tuning, troubleshooting and monitoring).  
- Able to deploy Hadoop cluster, add and remove nodes, troubleshoot failed jobs, configure and tune the cluster, monitor critical parts of the cluster, etc. 
 
Desirable Functional Skills:
-          Strong customer facing skill

-          Responsible for implementation and ongoing administration of Hadoop infrastructure.

-          Aligning with the systems engineering team to propose and deploy new hardware and software environments required for Hadoop and to expand existing environments.

-          Working with data delivery teams to setup new Hadoop users. This job includes setting up Linux users, setting up Kerberos principals and testing HDFS, Hive, Pig and MapReduce access for the new users.

-          Cluster maintenance as well as creation and removal of nodes using tools like,Cloudera Manager Enterprise, and other tools.

-          Performance tuning of Hadoop clusters and Hadoop MapReduce routines.

-          Screen Hadoop cluster job performances and capacity planning

-          Monitor Hadoop cluster connectivity and security

-          Manage and review Hadoop log files.

-          File system management and monitoring.

-          HDFS support and maintenance.

-          Strong verbal and writtent communication to collaborate with business group members 
=====================================================================================================
Able to deploy Hadoop cluster, add and remove nodes, troubleshoot failed jobs, configure and tune the cluster, monitor critical parts of the cluster, etc.  

路         Responsible for implementation and ongoing administration of Hadoop infrastructure. Aligning with the systems engineering team to propose and deploy new hardware and software environments required for Hadoop and to expand existing environments.

路         Working with data delivery teams to setup new Hadoop users. This job includes setting up Linux users, setting up Kerberos principals and testing HDFS, Hive, Pig and MapReduce access for the new users. Cluster maintenance as well as creation and removal of nodes using tools like,Cloudera Manager Enterprise, and other tools. Performance tuning of Hadoop clusters and Hadoop MapReduce routines.

路         Screen Hadoop cluster job performances and capacity planning. Monitor Hadoop cluster connectivity and security. Manage and review Hadoop log files.

路         File system management and monitoring. HDFS support and maintenance.

